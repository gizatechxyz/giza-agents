{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Verifiable Neural Network with Giza Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giza Agents provides developers with the tools to easily create and expand Verifiable Machine Learning solutions, transforming their Python scripts and ML models into robust, repeatable workflows. Models developed using the AI Agents possess a verifiable property, enabling you to encapsulate your model within a Zero-Knowledge cryptographic layer, thereby ensuring the integrity of the inference.\n",
    "\n",
    "In this tutorial, we will explore the process of building your first Neural Network using the MNIST dataset, [Pytorch](https://pytorch.org/), and Giza Agents and demonstrate its verifiability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the MNIST dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is an extensive collection of handwritten digits, very popular in the field of image processing. Often, it's used as a reference point for machine learning algorithms. This dataset conveniently comes already partitioned into training and testing sets, a feature we'll delve into later in this tutorial.\n",
    "\n",
    "The MNIST database comprises a collection of 70,000 images of handwritten digits, ranging from 0 to 9. Each image measures 28 x 28 pixels. For this tutorial, we will resize the image to 14 x 14 pixels.\n",
    "\n",
    "![MNIST Dataset illustration](./imgs/mnist_dataset_illustration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login to Giza and create a Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, it's important to note that since we will be using Giza tools, you need to log in to the Giza platform. To do this, we recommend following these steps to install the Giza CLI, create a user, and generate API keys:\n",
    "\n",
    "```bash\n",
    "$ pipx install giza-cli\n",
    "$ giza users create\n",
    "$ giza users login\n",
    "$ giza users create-api-key\n",
    "```\n",
    "\n",
    "For more detailed information about `login`, please refer to the [Giza-CLI documentation](https://cli.gizatech.xyz/welcome/readme)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we must define the architecture of our model. In this tutorial, we will construct a basic feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import logging\n",
    "from scipy.ndimage import zoom\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 196  # 14x14\n",
    "hidden_size = 10 \n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare your functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets and create loaders\n",
    "We need to download datasets and create loaders for both training and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images):\n",
    "    return np.array([zoom(image[0], (0.5, 0.5)) for image in images])\n",
    "\n",
    "def prepare_datasets():\n",
    "    print(\"Prepare dataset...\")\n",
    "    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False)\n",
    "\n",
    "    x_train = resize_images(train_dataset)\n",
    "    x_test = resize_images(test_dataset)\n",
    "\n",
    "    x_train = torch.tensor(x_train.reshape(-1, 14*14).astype('float32') / 255)\n",
    "    y_train = torch.tensor([label for _, label in train_dataset], dtype=torch.long)\n",
    "\n",
    "    x_test = torch.tensor(x_test.reshape(-1, 14*14).astype('float32') / 255)\n",
    "    y_test = torch.tensor([label for _, label in test_dataset], dtype=torch.long)\n",
    "\n",
    "    print(\"âœ… Datasets prepared successfully\")\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(x_train, y_train, x_test, y_test):\n",
    "    print(\"Create loaders...\")\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"âœ… Loaders created!\")\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "We need to define our training method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader):\n",
    "    print(\"Train model...\")\n",
    "\n",
    "    model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device).reshape(-1, 14*14)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    print(\"âœ… Model trained successfully\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model\n",
    "\n",
    "We need to define our testing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    print(\"Test model...\")\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device).reshape(-1, 14*14)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the functions\n",
    "\n",
    "Now that we've prepared the functions, we need to execute them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def execution():\n",
    "    x_train, y_train, x_test, y_test = prepare_datasets()\n",
    "    train_loader, test_loader = create_data_loaders(\n",
    "        x_train, y_train, x_test, y_test)\n",
    "    model = train_model(train_loader)\n",
    "    test_model(model, test_loader)\n",
    "\n",
    "\n",
    "execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and Prove!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, we have primarily focused on training and testing our model using PyTorch while monitoring its execution through the Giza platform. However, if you are here, it's likely because you want to harness the capabilities of ZKML (Zero-Knowledge Machine Learning) and have the ability to demonstrate the integrity of your model's inferences.\n",
    "\n",
    "In this section, we will delve into what it means to prove the integrity of inferences, what setup is required to make this possible, and how to verify the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZKML leverages validity proofs like SNARKs and STARKs, which enables the verification of the correctness of computational processes. By deploying such proof systems in machine learning applications, we gain the ability to validate the inference of ML models or to confirm that a specific input produced a certain output with a given model.\n",
    "\n",
    "To generate ZK proofs for your model inferences, you must first convert your model into ZK circuits. This conversion process involves leveraging programming languages that specialize in building ZK circuits, such as [Cairo-lang](https://www.cairo-lang.org/). Subsequently, using the Giza-CLI, you can transpile your model from ONNX to Cairo. This process will be covered in the upcoming sections.\n",
    "\n",
    "It's worth mentioning that at present, Orion and Action-SDK exclusively support Cairo as a ZK backend. However, we are actively working on expanding support to other ZK backends (e.g; EZKL, Noir ...).\n",
    "\n",
    "![Giza Stack](./imgs/giza_stack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to ONNX\n",
    "\n",
    "Before invoking the Giza transpiler to convert your model into Cairo, you must first ensure that your model is converted to ONNX. We will explore this process in the following section.\n",
    "\n",
    "ONNX, short for Open Neural Network Exchange, is an open format for representing and exchanging machine learning models between different frameworks and libraries. It serves as an intermediary format that allows you to move models seamlessly between various platforms and tools, facilitating interoperability and flexibility in the machine learning ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "def convert_to_onnx(model, onnx_file_path):\n",
    "    dummy_input = torch.randn(1, input_size).to(device)\n",
    "    torch.onnx.export(model, dummy_input, onnx_file_path,\n",
    "                      export_params=True, opset_version=10, do_constant_folding=True)\n",
    "\n",
    "    print(f\"Model has been converted to ONNX and saved as {onnx_file_path}\")\n",
    "\n",
    "\n",
    "def execution():\n",
    "    x_train, y_train, x_test, y_test = prepare_datasets()\n",
    "    train_loader, test_loader = create_data_loaders(\n",
    "        x_train, y_train, x_test, y_test)\n",
    "    model = train_model(train_loader)\n",
    "    test_model(model, test_loader)\n",
    "\n",
    "    # Convert to ONNX\n",
    "    onnx_file_path = \"mnist_model.onnx\"\n",
    "    convert_to_onnx(model, onnx_file_path)\n",
    "\n",
    "\n",
    "execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpile your model to Cairo and deploy on Giza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these steps to transpile your model to Orion Cairo code, compile the transpiled project, and deploy it on the Giza platform.\n",
    "\n",
    "### Step 1: Transpile Your Model\n",
    "Now that your model is converted to ONNX format, use the Giza-CLI to transpile it to Orion Cairo code:\n",
    "\n",
    "```bash\n",
    "$ giza transpile mnist_model.onnx --output-path verifiable_mnist\n",
    ">>> \n",
    "[giza][2024-02-07 16:32:13.511] Transpilation is fully compatible. \n",
    "Version compiled and Sierra is saved at Giza âœ…\n",
    "```\n",
    "\n",
    "### Step 2: Deploy Your Model\n",
    "Thanks to the full support for all operators used by the MNIST model in the transpiler, your transpilation process is completely compatible. This ensures that your project compiles smoothly and has already been compiled behind the scenes on our platform. \n",
    "\n",
    "ðŸš¨: If your model incorporates operators that aren't supported by the transpiler, you may need to refine your Cairo project to ensure successful compilation. For more details, refer to the to [how-to-guide](https://actions.gizatech.xyz/how-to-guides/gizamodel#executing-verifiable-inference-with-gizamodel-and-onnx).\n",
    "\n",
    "With your model transpiled and compiled, it's now ready for deployment on the Giza platform. Our deployment process sets up services that handle prediction requests via a designated endpoint, using Cairo to ensure the provability of inferences.\n",
    "\n",
    "**Creating a New Deployment Service**\n",
    "\n",
    "Deploy your service, which will be ready to accept prediction requests at the /cairo_run endpoint, by using the following command:\n",
    "```bash\n",
    "giza deployments deploy --model-id <MODEL_ID> --version-id <VERSION_ID>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your program\n",
    "\n",
    "Now that your Cairo model is deployed on the Giza platform, you have the capability to execute it. If you initiate a prediction using Giza Agents without the `verifiable` mode, it runs the onnx version of the model.\n",
    "\n",
    "\n",
    "When you initiate a prediction using Giza Agents in `verifiable` mode, it executes the Sierra program using CairoVM, generating trace and memory files for the proving. It also returns the output value and initiates a proving job to generate a Stark proof of the inference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make a prediction with the ONNX model (`verifiable=False`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giza.agents.model import GizaModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "\n",
    "    # Load image, convert to grayscale, resize and normalize\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # Resize to match the input size of the model\n",
    "    image = image.resize((14, 14))\n",
    "    image = np.array(image).astype('float32') / 255\n",
    "    image = image.reshape(1, 196)  # Reshape to (1, 196) for model input\n",
    "    return image\n",
    "\n",
    "\n",
    "def prediction(image):\n",
    "    model = GizaModel(model_path=\"./mnist_model.onnx\")\n",
    "\n",
    "    result = model.predict(\n",
    "        input_feed={\"onnx::Gemm_0\": image}, verifiable=False\n",
    "    )\n",
    "\n",
    "    # Convert result to a PyTorch tensor\n",
    "    result_tensor = torch.tensor(result)\n",
    "    # Apply softmax to convert to probabilities\n",
    "    probabilities = F.softmax(result_tensor, dim=1)\n",
    "    # Use argmax to get the predicted class\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "    return predicted_class.item()\n",
    "\n",
    "\n",
    "def execution():\n",
    "    image = preprocess_image(\"./imgs/zero.png\")\n",
    "    predicted_digit = prediction(image)\n",
    "    print(f\"Predicted Digit: {predicted_digit}\")\n",
    "\n",
    "    return predicted_digit\n",
    "\n",
    "\n",
    "execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a prediction with the Cairo model (`verifiable=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giza.agents.model import GizaModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "MODEL_ID = 296  # Update with your model ID\n",
    "VERSION_ID = 1  # Update with your version ID\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "\n",
    "    # Load image, convert to grayscale, resize and normalize\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # Resize to match the input size of the model\n",
    "    image = image.resize((14, 14))\n",
    "    image = np.array(image).astype('float32') / 255\n",
    "    image = image.reshape(1, 196)  # Reshape to (1, 196) for model input\n",
    "    return image\n",
    "\n",
    "\n",
    "def prediction(image, model_id, version_id):\n",
    "    model = GizaModel(id=model_id, version=version_id)\n",
    "\n",
    "    (result, request_id) = model.predict(\n",
    "        input_feed={\"image\": image}, verifiable=True\n",
    "    )\n",
    "\n",
    "    # Convert result to a PyTorch tensor\n",
    "    probabilities = torch.tensor(result)\n",
    "    # Use argmax to get the predicted class\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "    return predicted_class, request_id\n",
    "\n",
    "\n",
    "def execution():\n",
    "    image = preprocess_image(\"./imgs/zero.png\")\n",
    "    (result, request_id) = prediction(image, MODEL_ID, VERSION_ID)\n",
    "    print(\"Result: \", result)\n",
    "    print(\"Request id: \", request_id)\n",
    "\n",
    "    return result, request_id\n",
    "\n",
    "\n",
    "execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Verify the proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you ran your model, CairoVM generated trace and memory files under the hood to prove your program. We have initiated a proof job on your behalf and completed the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we will download the ZK proof generated in the proof-job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from giza.cli import API_HOST\n",
    "\n",
    "MODEL_ID = 199  # Update with your model ID\n",
    "VERSION_ID = 5  # Update with your version ID\n",
    "DEPLOYMENT_ID = 3  # Update with your deployment id\n",
    "REQUEST_ID = \"YOUR_REQUEST_ID\"  # Update with your request id\n",
    "API_KEY = 'YOUR_API_KEY'  # Update with your API key\n",
    "\n",
    "url = f'{API_HOST}/api/v1/models/{MODEL_ID}/versions/{VERSION_ID}/deployments/{DEPLOYMENT_ID}/proofs/{REQUEST_ID}:download'\n",
    "\n",
    "headers = {\"X-API-KEY\": API_KEY}\n",
    "\n",
    "d_url = requests.get(url, headers=headers).json()[\"download_url\"]\n",
    "\n",
    "proof = requests.get(d_url)\n",
    "\n",
    "with open(\"zk.proof\", \"wb\") as f:\n",
    "     f.write(proof.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's verify the proof!\n",
    "All you need to do is simply run: \n",
    "```bash\n",
    "giza verify --proof PATH_TO_PROOF\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VoilÃ  ðŸŽ‰! You've learned how to use the entire Giza stack, from training your model to transpiling it to Cairo for verifiable execution. You've also learned how to verify the proof. We hope you've enjoyed this journey! If you have any questions, please feel free to join us on our [Discord](https://discord.gg/zF2dxSYk6Z), or [open an issue](https://github.com/gizatechxyz/actions-sdk/issues). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "giza-actions-mYf3m_Lk-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
